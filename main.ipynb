{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library, create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from module.layers.Dense import Dense\n",
    "from module.optimizer.Adam import Adam\n",
    "from module.layers.RNN import RNN\n",
    "from tensorflow import keras\n",
    "from module.Sequential import Sequential\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./dataset/DanhgiaSmartphone.csv\")\n",
    "data = df[[\"comment\", \"label\"]].values\n",
    "np.random.shuffle(data)\n",
    "print(len(data)) # 113\n",
    "train_data = data[:63]\n",
    "test_data = data[:63]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build word embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 6, 10)\n",
      "(63, 3)\n"
     ]
    }
   ],
   "source": [
    "# Hàm lấy word embedding cho 1 từ\n",
    "# get embedding vector for a word\n",
    "def get_wv(w):\n",
    "    try:\n",
    "        return w2v.wv[w]\n",
    "    except KeyError:\n",
    "        return w2v.wv[\"UNK\"]\n",
    "\n",
    "# Hàm tạo word embedding cho 1 tập dữ liệu \n",
    "# Get get embedding vector for the dataset\n",
    "def word_embedding(sentences):\n",
    "    sen_split = [[word for word in sen.lower().split()]for sen in sentences]\n",
    "    x = []\n",
    "    for s in sen_split:\n",
    "        v = []\n",
    "        for w in s:\n",
    "            v.append(get_wv(w))\n",
    "        x.append(v)\n",
    "    x = keras.preprocessing.sequence.pad_sequences(x, padding=\"post\", dtype=\"float32\")\n",
    "    return x\n",
    "\n",
    "\"\"\" # Train word embedding model use Word2Vec\n",
    "df = pd.read_csv(\"./dataset/Train.csv\")\n",
    "sen_embedding = df[\"comment\"]\n",
    "\n",
    "# Xóa dấu câu và số trong dataset dùng để xây dựng word embedding\n",
    "# Remove special characters and digit\n",
    "sen_embedding_clean = []\n",
    "for sen in sen_embedding:\n",
    "    clean_sen = re.sub(r'[^\\w\\s]', '', sen)\n",
    "    clean_sen = re.sub(r'\\d', '', clean_sen)\n",
    "    sen_embedding_clean.append(clean_sen)\n",
    "\n",
    "sen_embedding_clean = [[word for word in sen.lower().split()] for sen in sen_embedding_clean]\n",
    "w2v = Word2Vec(sen_embedding_clean, vector_size=10)\n",
    "unk_vector = np.random.randn(10)\n",
    "w2v.wv.add_vector(\"UNK\", unk_vector)\n",
    "w2v.save(\"test.model\")  \"\"\"\n",
    "w2v = Word2Vec.load(\"./warehouse/test.model\")\n",
    "\n",
    "x_train = word_embedding(train_data[:, 0])\n",
    "y_train = OneHotEncoder(sparse_output=False).fit_transform(train_data[:, 1].reshape(-1, 1))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  [==========]  loss: 0.3643, accuracy 42.86%\n",
      "Epoch 1  [==========]  loss: 0.3563, accuracy 47.62%\n",
      "Epoch 2  [==========]  loss: 0.3312, accuracy 49.21%\n",
      "Epoch 3  [==========]  loss: 0.2967, accuracy 53.97%\n",
      "Epoch 4  [==========]  loss: 0.2789, accuracy 53.97%\n",
      "Epoch 5  [==========]  loss: 0.2726, accuracy 58.73%\n",
      "Epoch 6  [==========]  loss: 0.2700, accuracy 57.14%\n",
      "Epoch 7  [==========]  loss: 0.2700, accuracy 57.14%\n",
      "Epoch 8  [==========]  loss: 0.2688, accuracy 57.14%\n",
      "Epoch 9  [==========]  loss: 0.2674, accuracy 57.14%\n",
      "Epoch 10 [==========]  loss: 0.2654, accuracy 55.56%\n",
      "Epoch 11 [==========]  loss: 0.2640, accuracy 55.56%\n",
      "Epoch 12 [==========]  loss: 0.2620, accuracy 57.14%\n",
      "Epoch 13 [==========]  loss: 0.2602, accuracy 57.14%\n",
      "Epoch 14 [==========]  loss: 0.2578, accuracy 60.32%\n",
      "Epoch 15 [==========]  loss: 0.2554, accuracy 61.90%\n",
      "Epoch 16 [==========]  loss: 0.2524, accuracy 63.49%\n",
      "Epoch 17 [==========]  loss: 0.2490, accuracy 61.90%\n",
      "Epoch 18 [==========]  loss: 0.2449, accuracy 65.08%\n",
      "Epoch 19 [==========]  loss: 0.2402, accuracy 63.49%\n",
      "Epoch 20 [==========]  loss: 0.2349, accuracy 66.67%\n",
      "Epoch 21 [==========]  loss: 0.2292, accuracy 68.25%\n",
      "Epoch 22 [==========]  loss: 0.2234, accuracy 69.84%\n",
      "Epoch 23 [==========]  loss: 0.2177, accuracy 73.02%\n",
      "Epoch 24 [==========]  loss: 0.2119, accuracy 73.02%\n",
      "Epoch 25 [==========]  loss: 0.2062, accuracy 74.60%\n",
      "Epoch 26 [==========]  loss: 0.2005, accuracy 74.60%\n",
      "Epoch 27 [==========]  loss: 0.1947, accuracy 74.60%\n",
      "Epoch 28 [==========]  loss: 0.1887, accuracy 74.60%\n",
      "Epoch 29 [==========]  loss: 0.1825, accuracy 74.60%\n",
      "Epoch 30 [==========]  loss: 0.1760, accuracy 76.19%\n",
      "Epoch 31 [==========]  loss: 0.1696, accuracy 76.19%\n",
      "Epoch 32 [==========]  loss: 0.1632, accuracy 80.95%\n",
      "Epoch 33 [==========]  loss: 0.1567, accuracy 80.95%\n",
      "Epoch 34 [==========]  loss: 0.1500, accuracy 80.95%\n",
      "Epoch 35 [==========]  loss: 0.1434, accuracy 80.95%\n",
      "Epoch 36 [==========]  loss: 0.1368, accuracy 80.95%\n",
      "Epoch 37 [==========]  loss: 0.1298, accuracy 82.54%\n",
      "Epoch 38 [==========]  loss: 0.1236, accuracy 85.71%\n",
      "Epoch 39 [==========]  loss: 0.1178, accuracy 85.71%\n",
      "Epoch 40 [==========]  loss: 0.1126, accuracy 85.71%\n",
      "Epoch 41 [==========]  loss: 0.1080, accuracy 87.30%\n",
      "Epoch 42 [==========]  loss: 0.1037, accuracy 87.30%\n",
      "Epoch 43 [==========]  loss: 0.0998, accuracy 87.30%\n",
      "Epoch 44 [==========]  loss: 0.0962, accuracy 88.89%\n",
      "Epoch 45 [==========]  loss: 0.0927, accuracy 88.89%\n",
      "Epoch 46 [==========]  loss: 0.0894, accuracy 88.89%\n",
      "Epoch 47 [==========]  loss: 0.0862, accuracy 90.48%\n",
      "Epoch 48 [==========]  loss: 0.0832, accuracy 90.48%\n",
      "Epoch 49 [==========]  loss: 0.0801, accuracy 90.48%\n",
      "Epoch 50 [==========]  loss: 0.0771, accuracy 92.06%\n",
      "Epoch 51 [==========]  loss: 0.0742, accuracy 92.06%\n",
      "Epoch 52 [==========]  loss: 0.0713, accuracy 92.06%\n",
      "Epoch 53 [==========]  loss: 0.0685, accuracy 92.06%\n",
      "Epoch 54 [==========]  loss: 0.0659, accuracy 92.06%\n",
      "Epoch 55 [==========]  loss: 0.0633, accuracy 93.65%\n",
      "Epoch 56 [==========]  loss: 0.0607, accuracy 93.65%\n",
      "Epoch 57 [==========]  loss: 0.0585, accuracy 95.24%\n"
     ]
    }
   ],
   "source": [
    "from module.layers.LSTM import LSTM\n",
    "\n",
    "md = Sequential()\n",
    "md.add(LSTM(32, active=\"tanh\"))\n",
    "md.add(Dense(3, active=\"softmax\"))\n",
    "md.compile(optimizer=Adam(lr=0.003, beta1=0.9, beta2=0.99999))\n",
    "md.fit(X=x_train, y=y_train, batch_size=6, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "x_test = word_embedding(test_data[:, 0])\n",
    "y_test = OneHotEncoder(sparse_output=False).fit_transform(test_data[:, 1].reshape(-1, 1))\n",
    "pre, score = md.evalute(x_test, y_test)\n",
    "print(f\"Test accuracy: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
